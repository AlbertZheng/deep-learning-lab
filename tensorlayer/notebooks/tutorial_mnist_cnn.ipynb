{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tutorial_mnist_cnn.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/AlbertZheng/deep-learning-lab/blob/master/tensorlayer/notebooks/tutorial_mnist_cnn.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "ZWr1X-XM7_Nm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3057
        },
        "outputId": "ad00fcc8-5def-4d93-f9c3-7cdf9fc27786"
      },
      "cell_type": "code",
      "source": [
        "!pip install tensorlayer\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", message=\"numpy.dtype size changed\")\n",
        "warnings.filterwarnings(\"ignore\", message=\"numpy.ufunc size changed\")\n",
        "warnings.filterwarnings(\"ignore\", message=\"Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated\")\n",
        "\n",
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'\n",
        "\n",
        "\n",
        "import time\n",
        "import tensorflow as tf\n",
        "import tensorlayer as tl\n",
        "\n",
        "tf.logging.set_verbosity(tf.logging.DEBUG)\n",
        "tl.logging.set_verbosity(tl.logging.DEBUG)\n",
        "\n",
        "def main_test_cnn_layer():\n",
        "    \"\"\"Reimplementation of the TensorFlow official MNIST CNN tutorials:\n",
        "    - https://www.tensorflow.org/versions/r0.8/tutorials/mnist/pros/index.html\n",
        "    - https://github.com/tensorflow/tensorflow/blob/master/tensorflow/models/image/mnist/convolutional.py\n",
        "\n",
        "    More TensorFlow official CNN tutorials can be found here:\n",
        "    - tutorial_cifar10.py\n",
        "    - https://www.tensorflow.org/versions/master/tutorials/deep_cnn/index.html\n",
        "\n",
        "    - For simplified CNN layer see \"Convolutional layer (Simplified)\"\n",
        "      in read the docs website.\n",
        "    \"\"\"\n",
        "    X_train, y_train, X_val, y_val, X_test, y_test = tl.files.load_mnist_dataset(shape=(-1, 28, 28, 1))\n",
        "\n",
        "    sess = tf.InteractiveSession()\n",
        "\n",
        "    # Define the batchsize at the begin, you can give the batchsize in x and y_label\n",
        "    # rather than 'None', this can allow TensorFlow to apply some optimizations\n",
        "    # â€“ especially for convolutional layers.\n",
        "    batch_size = 128\n",
        "\n",
        "    x = tf.placeholder(tf.float32, shape=[batch_size, 28, 28, 1])  # [batch_size, height, width, channels]\n",
        "    y_label = tf.placeholder(tf.int64, shape=[batch_size])\n",
        "\n",
        "    net = tl.layers.InputLayer(x, name='input')\n",
        "    # Professional conv API for tensorflow expert\n",
        "    # net = tl.layers.Conv2dLayer(net,\n",
        "    #                     act = tf.nn.relu,\n",
        "    #                     shape = [5, 5, 1, 32],  # 32 features for each 5x5 patch\n",
        "    #                     strides=[1, 1, 1, 1],\n",
        "    #                     padding='SAME',\n",
        "    #                     name ='cnn1')     # output: (?, 28, 28, 32)\n",
        "    # net = tl.layers.PoolLayer(net,\n",
        "    #                     ksize=[1, 2, 2, 1],\n",
        "    #                     strides=[1, 2, 2, 1],\n",
        "    #                     padding='SAME',\n",
        "    #                     pool = tf.nn.max_pool,\n",
        "    #                     name ='pool1',)   # output: (?, 14, 14, 32)\n",
        "    # net = tl.layers.Conv2dLayer(net,\n",
        "    #                     act = tf.nn.relu,\n",
        "    #                     shape = [5, 5, 32, 64], # 64 features for each 5x5 patch\n",
        "    #                     strides=[1, 1, 1, 1],\n",
        "    #                     padding='SAME',\n",
        "    #                     name ='cnn2')     # output: (?, 14, 14, 64)\n",
        "    # net = tl.layers.PoolLayer(net,\n",
        "    #                     ksize=[1, 2, 2, 1],\n",
        "    #                     strides=[1, 2, 2, 1],\n",
        "    #                     padding='SAME',\n",
        "    #                     pool = tf.nn.max_pool,\n",
        "    #                     name ='pool2',)   # output: (?, 7, 7, 64)\n",
        "    # Simplified conv API (the same with the above layers)\n",
        "    net = tl.layers.Conv2d(net, 32, (5, 5), (1, 1), act=tf.nn.relu, padding='SAME', name='cnn1')\n",
        "    net = tl.layers.MaxPool2d(net, (2, 2), (2, 2), padding='SAME', name='pool1')\n",
        "    net = tl.layers.Conv2d(net, 64, (5, 5), (1, 1), act=tf.nn.relu, padding='SAME', name='cnn2')\n",
        "    net = tl.layers.MaxPool2d(net, (2, 2), (2, 2), padding='SAME', name='pool2')\n",
        "    # end of conv\n",
        "    net = tl.layers.FlattenLayer(net, name='flatten')\n",
        "    net = tl.layers.DropoutLayer(net, keep=0.5, name='drop1')\n",
        "    net = tl.layers.DenseLayer(net, 256, act=tf.nn.relu, name='relu1')\n",
        "    net = tl.layers.DropoutLayer(net, keep=0.5, name='drop2')\n",
        "    net = tl.layers.DenseLayer(net, 10, act=None, name='output')\n",
        "\n",
        "    y_pred = net.outputs\n",
        "\n",
        "    cost = tl.cost.cross_entropy(y_pred, y_label, 'cost')\n",
        "\n",
        "    correct_prediction = tf.equal(tf.argmax(y_pred, 1), y_label)\n",
        "    acc = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "\n",
        "    # train\n",
        "    n_epoch = 200\n",
        "    learning_rate = 0.0001\n",
        "    print_freq = 10\n",
        "\n",
        "    train_params = net.all_params\n",
        "    train_op = tf.train.AdamOptimizer(learning_rate).minimize(cost, var_list=train_params)\n",
        "\n",
        "    tl.layers.initialize_global_variables(sess)\n",
        "    net.print_params()\n",
        "    net.print_layers()\n",
        "\n",
        "    print('   learning_rate: %f' % learning_rate)\n",
        "    print('   batch_size: %d' % batch_size)\n",
        "\n",
        "    training_begin_time = time.time()\n",
        "    for epoch in range(n_epoch):\n",
        "        start_time = time.time()\n",
        "\n",
        "        for X_train_a, y_train_a in tl.iterate.minibatches(X_train, y_train, batch_size, shuffle=True):\n",
        "            feed_dict = {x: X_train_a, y_label: y_train_a}\n",
        "            feed_dict.update(net.all_drop)  # enable noise layers\n",
        "            sess.run(train_op, feed_dict=feed_dict)\n",
        "\n",
        "        if epoch + 1 == 1 or (epoch + 1) % print_freq == 0:\n",
        "            training_end_time = time.time()\n",
        "            print(\"Epoch %d of %d took %fs\" % (epoch + 1, n_epoch, training_end_time - start_time))\n",
        "            \n",
        "            train_loss, train_acc, n_batch = 0, 0, 0\n",
        "            for X_train_a, y_train_a in tl.iterate.minibatches(X_train, y_train, batch_size, shuffle=True):\n",
        "                dp_dict = tl.utils.dict_to_one(net.all_drop)  # disable noise layers\n",
        "                feed_dict = {x: X_train_a, y_label: y_train_a}\n",
        "                feed_dict.update(dp_dict)\n",
        "                err, ac = sess.run([cost, acc], feed_dict=feed_dict)\n",
        "                train_loss += err\n",
        "                train_acc += ac\n",
        "                n_batch += 1\n",
        "            print(\"   train loss: %f\" % (train_loss / n_batch))\n",
        "            print(\"   train acc: %f\" % (train_acc / n_batch))\n",
        "\n",
        "            val_loss, val_acc, n_batch = 0, 0, 0\n",
        "            for X_val_a, y_val_a in tl.iterate.minibatches(X_val, y_val, batch_size, shuffle=True):\n",
        "                dp_dict = tl.utils.dict_to_one(net.all_drop)  # disable noise layers\n",
        "                feed_dict = {x: X_val_a, y_label: y_val_a}\n",
        "                feed_dict.update(dp_dict)\n",
        "                err, ac = sess.run([cost, acc], feed_dict=feed_dict)\n",
        "                val_loss += err\n",
        "                val_acc += ac\n",
        "                n_batch += 1\n",
        "            print(\"   val loss: %f\" % (val_loss / n_batch))\n",
        "            print(\"   val acc: %f\" % (val_acc / n_batch))\n",
        "\n",
        "            # try:\n",
        "            #     tl.vis.CNN2d(net.all_params[0].eval(), second=10, saveable=True, name='cnn1_' + str(epoch + 1), fig_idx=2012)\n",
        "            # except:  # pylint: disable=bare-except\n",
        "            #     print(\"You should change vis.CNN(), if you want to save the feature images for different dataset\")\n",
        "\n",
        "    print('Total training time: %fs', training_end_time - training_begin_time)\n",
        "    \n",
        "    print('Start testing the network ...')\n",
        "    test_loss, test_acc, n_batch = 0, 0, 0\n",
        "    for X_test_a, y_test_a in tl.iterate.minibatches(X_test, y_test, batch_size, shuffle=True):\n",
        "        dp_dict = tl.utils.dict_to_one(net.all_drop)  # disable noise layers\n",
        "        feed_dict = {x: X_test_a, y_label: y_test_a}\n",
        "        feed_dict.update(dp_dict)\n",
        "        err, ac = sess.run([cost, acc], feed_dict=feed_dict)\n",
        "        test_loss += err\n",
        "        test_acc += ac\n",
        "        n_batch += 1\n",
        "    print(\"   test loss: %f\" % (test_loss / n_batch))\n",
        "    print(\"   test acc: %f\" % (test_acc / n_batch))\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # CNN\n",
        "    main_test_cnn_layer()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorlayer in /usr/local/lib/python3.6/dist-packages (1.10.1)\n",
            "Requirement already satisfied: matplotlib<2.3,>=2.2 in /usr/local/lib/python3.6/dist-packages (from tensorlayer) (2.2.3)\n",
            "Requirement already satisfied: progressbar2<3.39,>=3.38 in /usr/local/lib/python3.6/dist-packages (from tensorlayer) (3.38.0)\n",
            "Requirement already satisfied: lxml<4.3,>=4.2 in /usr/local/lib/python3.6/dist-packages (from tensorlayer) (4.2.5)\n",
            "Requirement already satisfied: wrapt<1.11,>=1.10 in /usr/local/lib/python3.6/dist-packages (from tensorlayer) (1.10.11)\n",
            "Requirement already satisfied: scipy<1.2,>=1.1 in /usr/local/lib/python3.6/dist-packages (from tensorlayer) (1.1.0)\n",
            "Requirement already satisfied: scikit-learn<0.20,>=0.19 in /usr/local/lib/python3.6/dist-packages (from tensorlayer) (0.19.2)\n",
            "Requirement already satisfied: scikit-image<0.15,>=0.14 in /usr/local/lib/python3.6/dist-packages (from tensorlayer) (0.14.0)\n",
            "Requirement already satisfied: requests<2.20,>=2.19 in /usr/local/lib/python3.6/dist-packages (from tensorlayer) (2.19.1)\n",
            "Requirement already satisfied: numpy<1.16,>=1.14 in /usr/local/lib/python3.6/dist-packages (from tensorlayer) (1.14.5)\n",
            "Requirement already satisfied: tqdm<4.26,>=4.23 in /usr/local/lib/python3.6/dist-packages (from tensorlayer) (4.25.0)\n",
            "Requirement already satisfied: imageio<2.5,>=2.3 in /usr/local/lib/python3.6/dist-packages (from tensorlayer) (2.4.1)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib<2.3,>=2.2->tensorlayer) (1.11.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib<2.3,>=2.2->tensorlayer) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib<2.3,>=2.2->tensorlayer) (1.0.1)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from matplotlib<2.3,>=2.2->tensorlayer) (2018.5)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib<2.3,>=2.2->tensorlayer) (2.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib<2.3,>=2.2->tensorlayer) (2.5.3)\n",
            "Requirement already satisfied: python-utils>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from progressbar2<3.39,>=3.38->tensorlayer) (2.3.0)\n",
            "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image<0.15,>=0.14->tensorlayer) (5.2.0)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image<0.15,>=0.14->tensorlayer) (1.0.0)\n",
            "Requirement already satisfied: cloudpickle>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from scikit-image<0.15,>=0.14->tensorlayer) (0.5.6)\n",
            "Requirement already satisfied: networkx>=1.8 in /usr/local/lib/python3.6/dist-packages (from scikit-image<0.15,>=0.14->tensorlayer) (2.1)\n",
            "Requirement already satisfied: dask[array]>=0.9.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image<0.15,>=0.14->tensorlayer) (0.19.1)\n",
            "Requirement already satisfied: idna<2.8,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<2.20,>=2.19->tensorlayer) (2.6)\n",
            "Requirement already satisfied: urllib3<1.24,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<2.20,>=2.19->tensorlayer) (1.22)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<2.20,>=2.19->tensorlayer) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<2.20,>=2.19->tensorlayer) (2018.8.24)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib<2.3,>=2.2->tensorlayer) (39.1.0)\n",
            "Requirement already satisfied: decorator>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=1.8->scikit-image<0.15,>=0.14->tensorlayer) (4.3.0)\n",
            "Requirement already satisfied: toolz>=0.7.3; extra == \"array\" in /usr/local/lib/python3.6/dist-packages (from dask[array]>=0.9.0->scikit-image<0.15,>=0.14->tensorlayer) (0.9.0)\n",
            "[TL] Load or Download MNIST > data/mnist\n",
            "[TL] data/mnist/train-images-idx3-ubyte.gz\n",
            "[TL] data/mnist/t10k-images-idx3-ubyte.gz\n",
            "[TL] InputLayer  input: (128, 28, 28, 1)\n",
            "[TL] Conv2d cnn1: n_filter: 32 filter_size: (5, 5) strides: (1, 1) pad: SAME act: relu\n",
            "[TL] MaxPool2d pool1: filter_size: (2, 2) strides: (2, 2) padding: SAME\n",
            "[TL] Conv2d cnn2: n_filter: 64 filter_size: (5, 5) strides: (1, 1) pad: SAME act: relu\n",
            "[TL] MaxPool2d pool2: filter_size: (2, 2) strides: (2, 2) padding: SAME\n",
            "[TL] FlattenLayer flatten: 3136\n",
            "[TL] DropoutLayer drop1: keep: 0.500000 is_fix: False\n",
            "[TL] DenseLayer  relu1: 256 relu\n",
            "[TL] DropoutLayer drop2: keep: 0.500000 is_fix: False\n",
            "[TL] DenseLayer  output: 10 No Activation\n",
            "[TL] WARNING: Function: `tensorlayer.layers.utils.initialize_global_variables` (in file: /usr/local/lib/python3.6/dist-packages/tensorlayer/layers/utils.py) is deprecated and will be removed after 2018-09-30.\n",
            "Instructions for updating: This API is deprecated in favor of `tf.global_variables_initializer`\n",
            "\n",
            "[TL]   param   0: cnn1/kernel:0        (5, 5, 1, 32)      float32_ref (mean: -0.00015238593914546072, median: -0.0002905193832702935, std: 0.01853932812809944)   \n",
            "[TL]   param   1: cnn1/bias:0          (32,)              float32_ref (mean: 0.0               , median: 0.0               , std: 0.0               )   \n",
            "[TL]   param   2: cnn2/kernel:0        (5, 5, 32, 64)     float32_ref (mean: 4.13294628742733e-06, median: 3.788262256421149e-05, std: 0.01762240007519722)   \n",
            "[TL]   param   3: cnn2/bias:0          (64,)              float32_ref (mean: 0.0               , median: 0.0               , std: 0.0               )   \n",
            "[TL]   param   4: relu1/W:0            (3136, 256)        float32_ref (mean: -5.148956006451044e-06, median: 2.3380272978101857e-05, std: 0.08803688734769821)   \n",
            "[TL]   param   5: relu1/b:0            (256,)             float32_ref (mean: 0.0               , median: 0.0               , std: 0.0               )   \n",
            "[TL]   param   6: output/W:0           (256, 10)          float32_ref (mean: -0.0013225176371634007, median: -0.0011651352979242802, std: 0.08943091332912445)   \n",
            "[TL]   param   7: output/b:0           (10,)              float32_ref (mean: 0.0               , median: 0.0               , std: 0.0               )   \n",
            "[TL]   num of params: 857738\n",
            "[TL]   layer   0: Placeholder:0        (128, 28, 28, 1)    float32\n",
            "[TL]   layer   1: cnn1/Relu:0          (128, 28, 28, 32)    float32\n",
            "[TL]   layer   2: pool1/MaxPool:0      (128, 14, 14, 32)    float32\n",
            "[TL]   layer   3: cnn2/Relu:0          (128, 14, 14, 64)    float32\n",
            "[TL]   layer   4: pool2/MaxPool:0      (128, 7, 7, 64)    float32\n",
            "[TL]   layer   5: flatten:0            (128, 3136)        float32\n",
            "[TL]   layer   6: drop1/mul:0          (128, 3136)        float32\n",
            "[TL]   layer   7: relu1/Relu:0         (128, 256)         float32\n",
            "[TL]   layer   8: drop2/mul:0          (128, 256)         float32\n",
            "[TL]   layer   9: output/bias_add:0    (128, 10)          float32\n",
            "   learning_rate: 0.000100\n",
            "   batch_size: 128\n",
            "Epoch 1 of 200 took 6.019990s\n",
            "   train loss: 0.251338\n",
            "   train acc: 0.931110\n",
            "   val loss: 0.224776\n",
            "   val acc: 0.942007\n",
            "Epoch 10 of 200 took 5.155532s\n",
            "   train loss: 0.049560\n",
            "   train acc: 0.984776\n",
            "   val loss: 0.053700\n",
            "   val acc: 0.984876\n",
            "Epoch 20 of 200 took 5.157950s\n",
            "   train loss: 0.027597\n",
            "   train acc: 0.991787\n",
            "   val loss: 0.037489\n",
            "   val acc: 0.989884\n",
            "Epoch 30 of 200 took 5.155904s\n",
            "   train loss: 0.017579\n",
            "   train acc: 0.994431\n",
            "   val loss: 0.032661\n",
            "   val acc: 0.991086\n",
            "Epoch 40 of 200 took 5.149340s\n",
            "   train loss: 0.012023\n",
            "   train acc: 0.996394\n",
            "   val loss: 0.029225\n",
            "   val acc: 0.992188\n",
            "Epoch 50 of 200 took 5.165045s\n",
            "   train loss: 0.008156\n",
            "   train acc: 0.997676\n",
            "   val loss: 0.027908\n",
            "   val acc: 0.993089\n",
            "Epoch 60 of 200 took 5.151859s\n",
            "   train loss: 0.006255\n",
            "   train acc: 0.998217\n",
            "   val loss: 0.027298\n",
            "   val acc: 0.992688\n",
            "Epoch 70 of 200 took 5.149168s\n",
            "   train loss: 0.004546\n",
            "   train acc: 0.998698\n",
            "   val loss: 0.027812\n",
            "   val acc: 0.992989\n",
            "Epoch 80 of 200 took 5.158555s\n",
            "   train loss: 0.003358\n",
            "   train acc: 0.999018\n",
            "   val loss: 0.026688\n",
            "   val acc: 0.993690\n",
            "Epoch 90 of 200 took 5.148249s\n",
            "   train loss: 0.002512\n",
            "   train acc: 0.999339\n",
            "   val loss: 0.025729\n",
            "   val acc: 0.993490\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-d85d3509de36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;31m# CNN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m     \u001b[0mmain_test_cnn_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-1-d85d3509de36>\u001b[0m in \u001b[0;36mmain_test_cnn_layer\u001b[0;34m()\u001b[0m\n\u001b[1;32m    108\u001b[0m             \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mX_train_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_label\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my_train_a\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m             \u001b[0mfeed_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_drop\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# enable noise layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m             \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mprint_freq\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    875\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 877\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    878\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1098\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1100\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1101\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1270\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1272\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1273\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1274\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1276\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1277\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1278\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1279\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1280\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1261\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1262\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1263\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1349\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}