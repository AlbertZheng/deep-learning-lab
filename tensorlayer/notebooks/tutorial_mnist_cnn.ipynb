{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tutorial_mnist_cnn.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/AlbertZheng/deep-learning-lab/blob/master/tensorlayer/notebooks/tutorial_mnist_cnn.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "uMe6GCMyZKa8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install tensorlayer\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", message=\"numpy.dtype size changed\")\n",
        "warnings.filterwarnings(\"ignore\", message=\"numpy.ufunc size changed\")\n",
        "warnings.filterwarnings(\"ignore\", message=\"Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated\")\n",
        "\n",
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'\n",
        "\n",
        "\n",
        "import time\n",
        "import tensorflow as tf\n",
        "import tensorlayer as tl\n",
        "\n",
        "tf.logging.set_verbosity(tf.logging.DEBUG)\n",
        "tl.logging.set_verbosity(tl.logging.DEBUG)\n",
        "\n",
        "def main_test_cnn_layer():\n",
        "    \"\"\"Reimplementation of the TensorFlow official MNIST CNN tutorials:\n",
        "    - https://www.tensorflow.org/versions/r0.8/tutorials/mnist/pros/index.html\n",
        "    - https://github.com/tensorflow/tensorflow/blob/master/tensorflow/models/image/mnist/convolutional.py\n",
        "\n",
        "    More TensorFlow official CNN tutorials can be found here:\n",
        "    - tutorial_cifar10.py\n",
        "    - https://www.tensorflow.org/versions/master/tutorials/deep_cnn/index.html\n",
        "\n",
        "    - For simplified CNN layer see \"Convolutional layer (Simplified)\"\n",
        "      in read the docs website.\n",
        "    \"\"\"\n",
        "    X_train, y_train, X_val, y_val, X_test, y_test = tl.files.load_mnist_dataset(shape=(-1, 28, 28, 1))\n",
        "\n",
        "    sess = tf.InteractiveSession()\n",
        "\n",
        "    # Define the batchsize at the begin, you can give the batchsize in x and y_label\n",
        "    # rather than 'None', this can allow TensorFlow to apply some optimizations\n",
        "    # â€“ especially for convolutional layers.\n",
        "    batch_size = 128\n",
        "\n",
        "    x = tf.placeholder(tf.float32, shape=[batch_size, 28, 28, 1])  # [batch_size, height, width, channels]\n",
        "    y_label = tf.placeholder(tf.int64, shape=[batch_size])\n",
        "\n",
        "    net = tl.layers.InputLayer(x, name='input')\n",
        "    # Professional conv API for tensorflow expert\n",
        "    # net = tl.layers.Conv2dLayer(net,\n",
        "    #                     act = tf.nn.relu,\n",
        "    #                     shape = [5, 5, 1, 32],  # 32 features for each 5x5 patch\n",
        "    #                     strides=[1, 1, 1, 1],\n",
        "    #                     padding='SAME',\n",
        "    #                     name ='cnn1')     # output: (?, 28, 28, 32)\n",
        "    # net = tl.layers.PoolLayer(net,\n",
        "    #                     ksize=[1, 2, 2, 1],\n",
        "    #                     strides=[1, 2, 2, 1],\n",
        "    #                     padding='SAME',\n",
        "    #                     pool = tf.nn.max_pool,\n",
        "    #                     name ='pool1',)   # output: (?, 14, 14, 32)\n",
        "    # net = tl.layers.Conv2dLayer(net,\n",
        "    #                     act = tf.nn.relu,\n",
        "    #                     shape = [5, 5, 32, 64], # 64 features for each 5x5 patch\n",
        "    #                     strides=[1, 1, 1, 1],\n",
        "    #                     padding='SAME',\n",
        "    #                     name ='cnn2')     # output: (?, 14, 14, 64)\n",
        "    # net = tl.layers.PoolLayer(net,\n",
        "    #                     ksize=[1, 2, 2, 1],\n",
        "    #                     strides=[1, 2, 2, 1],\n",
        "    #                     padding='SAME',\n",
        "    #                     pool = tf.nn.max_pool,\n",
        "    #                     name ='pool2',)   # output: (?, 7, 7, 64)\n",
        "    # Simplified conv API (the same with the above layers)\n",
        "    net = tl.layers.Conv2d(net, 32, (5, 5), (1, 1), act=tf.nn.relu, padding='SAME', name='cnn1')\n",
        "    net = tl.layers.MaxPool2d(net, (2, 2), (2, 2), padding='SAME', name='pool1')\n",
        "    net = tl.layers.Conv2d(net, 64, (5, 5), (1, 1), act=tf.nn.relu, padding='SAME', name='cnn2')\n",
        "    net = tl.layers.MaxPool2d(net, (2, 2), (2, 2), padding='SAME', name='pool2')\n",
        "    # end of conv\n",
        "    net = tl.layers.FlattenLayer(net, name='flatten')\n",
        "    net = tl.layers.DropoutLayer(net, keep=0.5, name='drop1')\n",
        "    net = tl.layers.DenseLayer(net, 256, act=tf.nn.relu, name='relu1')\n",
        "    net = tl.layers.DropoutLayer(net, keep=0.5, name='drop2')\n",
        "    net = tl.layers.DenseLayer(net, 10, act=None, name='output')\n",
        "\n",
        "    y_pred = net.outputs\n",
        "\n",
        "    cost = tl.cost.cross_entropy(y_pred, y_label, 'cost')\n",
        "\n",
        "    correct_prediction = tf.equal(tf.argmax(y_pred, 1), y_label)\n",
        "    acc = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "\n",
        "    # train\n",
        "    n_epoch = 200\n",
        "    learning_rate = 0.0001\n",
        "    print_freq = 10\n",
        "\n",
        "    train_params = net.all_params\n",
        "    train_op = tf.train.AdamOptimizer(learning_rate).minimize(cost, var_list=train_params)\n",
        "\n",
        "    tl.layers.initialize_global_variables(sess)\n",
        "    net.print_params()\n",
        "    net.print_layers()\n",
        "\n",
        "    print('   learning_rate: %f' % learning_rate)\n",
        "    print('   batch_size: %d' % batch_size)\n",
        "\n",
        "    training_begin_time = time.time()\n",
        "    for epoch in range(n_epoch):\n",
        "        start_time = time.time()\n",
        "\n",
        "        for X_train_a, y_train_a in tl.iterate.minibatches(X_train, y_train, batch_size, shuffle=True):\n",
        "            feed_dict = {x: X_train_a, y_label: y_train_a}\n",
        "            feed_dict.update(net.all_drop)  # enable noise layers\n",
        "            sess.run(train_op, feed_dict=feed_dict)\n",
        "\n",
        "        if epoch + 1 == 1 or (epoch + 1) % print_freq == 0:\n",
        "            training_end_time = time.time()\n",
        "            print(\"Epoch %d of %d took %fs\" % (epoch + 1, n_epoch, training_end_time - start_time))\n",
        "            \n",
        "            train_loss, train_acc, n_batch = 0, 0, 0\n",
        "            for X_train_a, y_train_a in tl.iterate.minibatches(X_train, y_train, batch_size, shuffle=True):\n",
        "                dp_dict = tl.utils.dict_to_one(net.all_drop)  # disable noise layers\n",
        "                feed_dict = {x: X_train_a, y_label: y_train_a}\n",
        "                feed_dict.update(dp_dict)\n",
        "                err, ac = sess.run([cost, acc], feed_dict=feed_dict)\n",
        "                train_loss += err\n",
        "                train_acc += ac\n",
        "                n_batch += 1\n",
        "            print(\"   train loss: %f\" % (train_loss / n_batch))\n",
        "            print(\"   train acc: %f\" % (train_acc / n_batch))\n",
        "\n",
        "            val_loss, val_acc, n_batch = 0, 0, 0\n",
        "            for X_val_a, y_val_a in tl.iterate.minibatches(X_val, y_val, batch_size, shuffle=True):\n",
        "                dp_dict = tl.utils.dict_to_one(net.all_drop)  # disable noise layers\n",
        "                feed_dict = {x: X_val_a, y_label: y_val_a}\n",
        "                feed_dict.update(dp_dict)\n",
        "                err, ac = sess.run([cost, acc], feed_dict=feed_dict)\n",
        "                val_loss += err\n",
        "                val_acc += ac\n",
        "                n_batch += 1\n",
        "            print(\"   val loss: %f\" % (val_loss / n_batch))\n",
        "            print(\"   val acc: %f\" % (val_acc / n_batch))\n",
        "\n",
        "            # try:\n",
        "            #     tl.vis.CNN2d(net.all_params[0].eval(), second=10, saveable=True, name='cnn1_' + str(epoch + 1), fig_idx=2012)\n",
        "            # except:  # pylint: disable=bare-except\n",
        "            #     print(\"You should change vis.CNN(), if you want to save the feature images for different dataset\")\n",
        "\n",
        "    print('Total training time: %fs', % (training_end_time - training_begin_time))\n",
        "    \n",
        "    print('Start testing the network ...')\n",
        "    test_loss, test_acc, n_batch = 0, 0, 0\n",
        "    for X_test_a, y_test_a in tl.iterate.minibatches(X_test, y_test, batch_size, shuffle=True):\n",
        "        dp_dict = tl.utils.dict_to_one(net.all_drop)  # disable noise layers\n",
        "        feed_dict = {x: X_test_a, y_label: y_test_a}\n",
        "        feed_dict.update(dp_dict)\n",
        "        err, ac = sess.run([cost, acc], feed_dict=feed_dict)\n",
        "        test_loss += err\n",
        "        test_acc += ac\n",
        "        n_batch += 1\n",
        "    print(\"   test loss: %f\" % (test_loss / n_batch))\n",
        "    print(\"   test acc: %f\" % (test_acc / n_batch))\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # CNN\n",
        "    main_test_cnn_layer()\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}